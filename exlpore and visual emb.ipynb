{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ec8ba3-219b-4505-b376-696fbda403a4",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5720d2-2a81-4381-81b7-d79bb0dae045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e016380-0888-4493-82ac-cd7537bc2f1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb6ba8-2335-4918-a4d9-cb56c22a4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_test_parquet = [\n",
    "    \"https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/test_part_0001.snappy.parquet\",\n",
    "    \"https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/test_part_0002.snappy.parquet\",\n",
    "]\n",
    "\n",
    "urls_test = []\n",
    "urls_test+= [f\"https://storage.yandexcloud.net/avitotechmlchallenge2025-2/test_title_images_decr/part_0001-0002-chunk_000{i}.zip\" for i in range(1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5fe05-26c2-40fb-a7b1-075daab2da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_train_parquet = [\n",
    "    \"https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/train_part_0001.snappy.parquet\",\n",
    "    \"https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/train_part_0002.snappy.parquet\",\n",
    "    \"https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/train_part_0003.snappy.parquet\",\n",
    "    \"https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/train_part_0004.snappy.parquet\",\n",
    "]\n",
    "\n",
    "urls_train = []\n",
    "urls_train+= [f\"https://storage.yandexcloud.net/avitotechmlchallenge2025-2/train_title_images_decr/train_images_part_0001-chunk_000{i}.zip\" for i in range(1, 8)]\n",
    "urls_train+= [f\"https://storage.yandexcloud.net/avitotechmlchallenge2025-2/train_title_images_decr/train_images_part_0002-chunk_000{i}.zip\" for i in range(1, 8)]\n",
    "urls_train+= [f\"https://storage.yandexcloud.net/avitotechmlchallenge2025-2/train_title_images_decr/train_images_part_0003-chunk_000{i}.zip\" for i in range(1, 8)]\n",
    "urls_train+= [f\"https://storage.yandexcloud.net/avitotechmlchallenge2025-2/train_title_images_decr/train_images_part_0004-chunk_000{i}.zip\" for i in range(1, 6)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90ce7a-2101-4496-b2e5-4c84a2c6a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"avitotech_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1ea02-189c-4eb5-9187-5f349175fd9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43adf9aa-bec4-4464-99d7-5854a79293c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(output_dir, url):\n",
    "    filename = os.path.join(output_dir, url.split(\"/\")[-1])\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Already downloaded: {filename}\")\n",
    "        return filename\n",
    "\n",
    "    try:\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            total = int(r.headers.get('content-length', 0))\n",
    "            with open(filename, \"wb\") as f, tqdm(\n",
    "                desc=f\"Downloading {os.path.basename(filename)}\",\n",
    "                total=total,\n",
    "                unit='B',\n",
    "                unit_scale=True,\n",
    "                unit_divisor=1024,\n",
    "            ) as bar:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        bar.update(len(chunk))\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d8cfc-a36d-4e2a-b721-149e2417d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "    list(executor.map(download_file, output_dir, urls_train_parquet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c5743-0e58-452e-9f86-6a7f70f876f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "    list(executor.map(download_file, output_dir, urls_test_parquet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d435260-c411-42d1-adfe-5afeb6dda705",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f29d1-0543-47a6-ab00-d8891d3207a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_dir = \"unzipped\"\n",
    "os.makedirs(photo_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bbad12-6376-4917-8a93-59e4dee29122",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "    list(executor.map(download_file, \"train\", urls_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732d018-46be-4f26-acf8-4e84f2e839b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "    list(executor.map(download_file, \"test\", urls_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e62116-2d06-4a79-a915-159631b0c99e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check data from two frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4c7e7-5c07-4346-a957-e3e0c73dd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"train_part_0001.snappy.parquet\")\n",
    "df2 = pd.read_parquet(\"test_part_0001.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e311b-dd65-4079-a847-295c4b46a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "clms = set(df1.columns) | set(df2.columns)\n",
    "\n",
    "uni = set()\n",
    "inter = set()\n",
    "for cl in clms:\n",
    "    if cl not in df1.columns or cl not in df2.columns:\n",
    "        inter.add(cl)\n",
    "    else:\n",
    "        uni.add(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c7a9d-586c-444d-8a69-fcc1adeafea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd5870-c167-4f4c-9908-91e645fe4da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f787c80-0536-4fe1-91a8-8f860ddcafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41853f19-b2ad-4d08-a37c-edbd3943df31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25f700be-1b5e-4445-82a0-98d970b4fd0d",
   "metadata": {},
   "source": [
    "# Insides of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e63b84-5be8-497e-bfba-f89a41c7744d",
   "metadata": {},
   "source": [
    "## Loading test + train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f42db23-2e9e-4b16-9df1-b2296ee090eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f8761c-0d65-4918-9f48-839b5ec56515",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"avitotech_data\\\\avitotech_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28cf4216-0141-4edd-b15e-74af865a60fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1 = pd.read_parquet(\"train_part_0001.snappy.parquet\")\n",
    "df_train_2 = pd.read_parquet(\"train_part_0002.snappy.parquet\")\n",
    "df_train_3 = pd.read_parquet(\"train_part_0003.snappy.parquet\")\n",
    "df_train_4 = pd.read_parquet(\"train_part_0004.snappy.parquet\")\n",
    "\n",
    "df_test_1 = pd.read_parquet(\"test_part_0001.snappy.parquet\")\n",
    "df_test_2 = pd.read_parquet(\"test_part_0002.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11ec54f-b4e1-4238-a797-9d49ca2306d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In first  file: 500000\n",
      "In second file: 500000\n",
      "In third  file: 500000\n",
      "In forth  file: 379555\n",
      "Total : 1879555\n",
      "In first test: 250000\n",
      "In second test: 250000\n",
      "Total : 500000\n"
     ]
    }
   ],
   "source": [
    "print(f'In first  file: {len(df_train_1)}')\n",
    "print(f'In second file: {len(df_train_2)}')\n",
    "print(f'In third  file: {len(df_train_3)}')\n",
    "print(f'In forth  file: {len(df_train_4)}')\n",
    "print(f'Total : {len(df_train_1) + len(df_train_2) + len(df_train_3) + len(df_train_4)}')\n",
    "\n",
    "print(f'In first test: {len(df_test_1)}')\n",
    "print(f'In second test: {len(df_test_2)}')\n",
    "print(f'Total : {len(df_test_1) + len(df_test_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6445e4a-80d6-4c2e-845c-99fb53ff9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train_1, df_train_2, df_train_3, df_train_4])\n",
    "\n",
    "df_test = pd.concat([df_test_1, df_test_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ccca5c-7be2-4a4a-a6d5-df72b007c167",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6b9eae-3dfb-4955-b28d-05533a55ca1a",
   "metadata": {},
   "source": [
    "### Nulls check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29670bc7-56b0-4987-b7d0-f344460b2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum(df_train['base_item_id'].isnull()) != 0 or sum(df_train['cand_item_id'].isnull()) != 0:\n",
    "    print('Nulls!')\n",
    "elif sum(df_train['base_item_id'].isna()) != 0 or sum(df_train['cand_item_id'].isna()) != 0:\n",
    "    print('NAs!')\n",
    "else:\n",
    "    print('Excellent!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a3e37-98c9-4aa6-84a2-4da70fae2ab8",
   "metadata": {},
   "source": [
    "### Cnt pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7725aba-dcaf-4878-bc8e-fc9cd64edacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = df_train[['base_item_id', 'cand_item_id']].values\n",
    "unique_ids = set(pairs.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423bec9e-5263-46a4-8598-0ea488754298",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [sorted(pair) for pair in pairs]\n",
    "pairs.sort(key=lambda x: x[0])\n",
    "unique_pairs = set(tuple(pair) for pair in pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c637167-c03a-472f-b0a1-ab23e1681b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Всего пар: {len(pairs):,}\")\n",
    "print(f\"Всего уникальный пар: {len(unique_pairs):,}\")\n",
    "\n",
    "print(f\"Всего уникальный ID: {len(unique_ids):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27799b-a705-41ee-a690-a780ec47852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = 0\n",
    "\n",
    "for pair in pairs:\n",
    "    if pair[0] == pair[1]:\n",
    "        same += 1\n",
    "\n",
    "print(f'Количетсво сравнений одного предложения: {same}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035d054-d0e3-475e-a15c-3d883bc8219b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Проверка описаний"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e8bef-355a-421f-8205-5675218e47a0",
   "metadata": {},
   "source": [
    "### Уникальность значений и пересечение train - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47124616-a9a6-4bff-847e-42e00be50538",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Количество категорий base: {len(df_train['base_category_name'].unique())}\")\n",
    "print(f\"Категории base: {[el for el in df_train['base_category_name'].unique()]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Количество категорий cand: {len(df_train['cand_category_name'].unique())}\")\n",
    "print(f\"Категории cand: {[el for el in df_train['cand_category_name'].unique()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635949e-d5b3-4a92-94cd-afe84e59697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Количество подкатегорий base: {len(df_train['base_subcategory_name'].unique())}\")\n",
    "print(f\"Подкатегории base: {[el for el in df_train['base_subcategory_name'].unique()]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Количество подкатегорий cand: {len(df_train['cand_subcategory_name'].unique())}\")\n",
    "print(f\"Подкатегории cand: {[el for el in df_train['cand_subcategory_name'].unique()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0308b8-a20a-4ad0-ad8a-73dedaad46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Количество подкатегорий base: {len(df_train['base_param1'].unique())}\")\n",
    "print(f\"Подкатегории base: {sorted([el for el in df_train['base_param1'].unique() if el is not None])}\")\n",
    "print(f\"Есть ли None: {None in df_train['base_param1'].unique()}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Количество подкатегорий base: {len(df_train['cand_param1'].unique())}\")\n",
    "print(f\"Подкатегории base: {sorted([el for el in df_train['cand_param1'].unique() if el is not None])}\")\n",
    "print(f\"Есть ли None: {None in df_train['cand_param1'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1807d9b-4d16-4f8c-ae61-b41124a0f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Количество подкатегорий base: {len(df_train['base_param2'].unique())}\")\n",
    "print(f\"Подкатегории base: {sorted([el for el in df_train['base_param2'].unique() if el is not None])}\")\n",
    "print(f\"Есть ли None: {None in df_train['base_param2'].unique()}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Количество подкатегорий base: {len(df_train['cand_param2'].unique())}\")\n",
    "print(f\"Подкатегории base: {sorted([el for el in df_train['cand_param2'].unique() if el is not None])}\")\n",
    "print(f\"Есть ли None: {None in df_train['cand_param2'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5c414-1eac-4514-a94e-bed1b464ff12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Проверка цен"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade13930-fafd-4f31-9569-187e6d80990f",
   "metadata": {},
   "source": [
    "### Пустые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a50ca36-4a46-4b1e-a87b-7dbcd4491291",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(df_train['base_price'].isna()))\n",
    "print(sum(df_train['base_price'].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6dafc-8f61-4272-83d0-0e17cc87570e",
   "metadata": {},
   "source": [
    "### Очень большие и отрицательные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1cd00-3b41-4efa-a382-18a61647b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df_train['base_price'].apply(lambda x: np.trunc(x / 100_000) * 100_000 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f585152-eba3-4aab-93ae-9aa8899790b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(col.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba78a2b-1e11-499e-944e-30cd46c5f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['base_price'] > 900_000_000].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ce5d4-81d3-40d0-94ab-1fec97ce9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "col.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca1b5c-c31f-47b5-a395-69525e945930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['base_price'] == 0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e20c1f-e9a1-4129-99ea-8f7715d2f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['base_price'] == -1].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f83dc0-0f35-4c4a-ab28-f718aef8dc4b",
   "metadata": {},
   "source": [
    "**Результат:** Есть отрицательные значения и бесплатные. Часть из них действительно бесплатные (Отдам в хорошие руки).\n",
    "\n",
    "**Предположение:** если есть дубль с -1 и другой суммой, то такие данные порченные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663809ad-328a-4688-b059-eb7af1f6a061",
   "metadata": {},
   "source": [
    "### -1 explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676d252-64c1-475d-9201-96f73cb5e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = df_train[df_train.is_double == 1]\n",
    "df_def_prices = df_prices[df_prices.base_price == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0ae9e-b90f-4fa2-b556-7fcc44faa4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def_prices[df_def_prices.base_price != df_def_prices.cand_price][['base_price', 'cand_price']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6fbdb-072c-40ab-b86b-f822abb9b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def_prices[df_def_prices.base_price != df_def_prices.cand_price].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d2623-e90c-4a7c-86b2-82619cf3bcf8",
   "metadata": {},
   "source": [
    "**Результат:** для товаров с -1 можно 1. не рассматривать сумму, 2. считать сумму такой же, как и второй товар, если они в одной группе товаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e9ab-e754-4224-ab11-382ef584f6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "490e93e7-abf0-4f7a-84ab-5138ae73618c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## How duplicates are look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38553a76-1b08-4594-a7f2-4909be6307f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duples = df_train[df_train.is_double == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b416c-fb7f-4af7-bd31-669a184babed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duples.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798da09d-83d9-4221-8614-49eed6423d82",
   "metadata": {},
   "source": [
    "**Результат:** у кого то разные title/description\n",
    "\n",
    "Подробнее о других параметрах будет ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b198e-e435-42be-b286-08227c907764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f09387f-f5fc-453f-b72d-640b2f5a60d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Проверка JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f916038-07be-407b-83d3-3e79566bce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_params = {}\n",
    "\n",
    "for params in df_train['base_json_params']:\n",
    "    for param in json.loads(params):\n",
    "        if param not in dict_params:\n",
    "            dict_params[param] = 1\n",
    "        else:\n",
    "            dict_params[param] += 1\n",
    "\n",
    "dict_params = {k: v for k, v in sorted(dict_params.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(f\"Всего параметров: {len(dict_params)}\")\n",
    "types = {}\n",
    "\n",
    "for params in df_train['base_json_params']:\n",
    "    for key, val in json.loads(params).items():\n",
    "        if type(val) not in types:\n",
    "            types[type(val)] = 1\n",
    "        else:\n",
    "            types[type(val)] += 1\n",
    "\n",
    "print(f\"Количество параметров каждого типа: {types}\")\n",
    "types = {}\n",
    "\n",
    "for params in df_train['base_json_params']:\n",
    "    for key, val in json.loads(params).items():\n",
    "        tp = type(val).__name__\n",
    "        k = int(key)\n",
    "        if tp not in types:\n",
    "            types[tp] = [k]\n",
    "        else:\n",
    "            if k not in types[tp]:\n",
    "                types[tp].append(k)\n",
    "\n",
    "cnt_types = {}\n",
    "\n",
    "for lst in types.items():\n",
    "    cnt_types[lst[0]] = len(lst[1])\n",
    "\n",
    "print(f\"Количество признаков каждого типа: {cnt_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89c7a2-aee1-43cb-b077-1526eb826ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_params = {}\n",
    "\n",
    "for params in df_train['cand_json_params']:\n",
    "    for param in json.loads(params):\n",
    "        if param not in dict_params:\n",
    "            dict_params[param] = 1\n",
    "        else:\n",
    "            dict_params[param] += 1\n",
    "\n",
    "dict_params = {k: v for k, v in sorted(dict_params.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(f\"Всего параметров: {len(dict_params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde371f-fab6-4fe8-aad0-d05930a48b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = 0\n",
    "\n",
    "for params in df_train.base_json_params:\n",
    "    all_params = json.loads(params).keys()\n",
    "    if gp < len(all_params):\n",
    "        gp = len(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdff740-63bc-43af-bd12-6a958829c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Максимум параметров на одного: {gp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ef862-7240-49ab-b2aa-e6e73a2d4590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcd1a674-8f61-4760-984b-3abce25bb2dc",
   "metadata": {},
   "source": [
    "## Изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9967a5f-7a64-4123-9e7d-0bd7a3479d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"train\")\n",
    "zip_files = glob.glob('train_images_part_*-chunk_*.zip')\n",
    "\n",
    "for zip_path in zip_files:\n",
    "    print(f\"Распаковка: {zip_path}\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Извлекаем в папку с тем же именем, как ZIP-файл (без расширения)\n",
    "        folder_name = os.path.splitext(os.path.basename(zip_path))[0]\n",
    "        target_path = folder_name\n",
    "        os.makedirs(target_path, exist_ok=True)\n",
    "        zip_ref.extractall(target_path)\n",
    "\n",
    "print(\"✅ Все архивы распакованы.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec4337-95f1-4c00-9bf1-c08d9494719e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Битые/невалидные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7b0277-a798-46b2-9157-a3e8f873f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageStat\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from transformers import SiglipImageProcessor, SiglipVisionModel\n",
    "import torch, requests\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18ee66f-6889-494b-ac6f-2575124e4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"google/siglip-base-patch16-224\"\n",
    "model     = SiglipVisionModel.from_pretrained(model_id,\n",
    "                                              torch_dtype=torch.float16).to(device).eval()\n",
    "processor = SiglipImageProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bed068-617b-4927-bd58-c9248910b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('unzipped')\n",
    "photo_ref = glob.glob('train_images_part_000*-chunk_000*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b36a86-9038-49a0-8f05-97beff89d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_params = defaultdict(dict)\n",
    "error_size = defaultdict(list)\n",
    "error_other = defaultdict(list)\n",
    "\n",
    "for ref in photo_ref:\n",
    "    error_size[ref] = []\n",
    "    error_other[ref] = []\n",
    "    img_params[ref] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e673d11-bee7-488d-8a1a-1f747aeb054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(ref, filename):\n",
    "    try:\n",
    "        path = os.path.join(ref, filename)\n",
    "        with Image.open(path) as img:\n",
    "            img = img.convert(\"L\")\n",
    "            img.load()\n",
    "            \n",
    "            width, height = img.size\n",
    "            if width < 128 or height < 128:\n",
    "                return ('error_size', ref, filename)\n",
    "\n",
    "            stat = ImageStat.Stat(img)\n",
    "            hist = np.array(img.histogram())\n",
    "\n",
    "            hist = hist / hist.sum()\n",
    "            entropy = -np.sum(hist * np.log2(hist + 1e-10))\n",
    "\n",
    "            arr = np.array(img)\n",
    "            white_ratio = np.mean(arr > 250)\n",
    "            black_ratio = np.mean(arr < 5)\n",
    "\n",
    "            return ('success', ref, filename, {\n",
    "                \"stddev\": stat.stddev,\n",
    "                \"mean\": stat.mean,\n",
    "                \"entropy\": entropy,\n",
    "                \"white_ratio\": white_ratio,\n",
    "                \"black_ratio\": black_ratio\n",
    "            })\n",
    "    except Exception as e:\n",
    "        return ('error_other', ref, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01302fc9-5758-4add-b4da-6870bc8b203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor () as executor:\n",
    "    futures = []\n",
    "    for ref in tqdm(photo_ref):\n",
    "        names = os.listdir(ref)\n",
    "\n",
    "        for filename in tqdm(names):\n",
    "            futures.append(executor.submit(process_image, ref, filename))\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        result = future.result()\n",
    "        if result[0] == 'success':\n",
    "            _, ref, filename, params = result\n",
    "            img_params[ref][filename] = params\n",
    "        elif result[0] == 'error_size':\n",
    "            _, ref, filename = result\n",
    "            error_size[ref].append(filename)\n",
    "        elif result[0] == 'error_other':\n",
    "            _, ref, filename = result\n",
    "            error_other[ref].append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb0ee2-56f8-43d1-a7c5-3b9d5e09e5ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4219e88-312e-47e9-85e6-bdf9e629707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164324d-c3b9-446c-8e7a-4b8dbcbf355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"img_params.json\", \"w\") as fp:\n",
    "    json.dump(img_params , fp)\n",
    "\n",
    "with open(\"error_size.json\", \"w\") as fp:\n",
    "    json.dump(error_size , fp)\n",
    "    \n",
    "with open(\"error_other.json\", \"w\") as fp:\n",
    "    json.dump(error_other , fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda9cca-c8e7-419b-86bc-3a42a04d9910",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Определение количества корректных фото"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a6daff6-2114-41cd-ab5a-c9369c609b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"img_params.json\", \"r\") as file:\n",
    "    img_params = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2949095a-1d06-44cc-9862-eddd15f0dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref in img_params:\n",
    "    for filename in img_params[ref]:\n",
    "        img_params[ref][filename]['use'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39dbc14a-8330-4049-8ca5-923509e70656",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref in img_params:\n",
    "    for filename in img_params[ref]:\n",
    "        if   img_params[ref][filename]['stddev'][0] < 25:\n",
    "             img_params[ref][filename]['use'] = 0\n",
    "        elif img_params[ref][filename]['black_ratio'] > 0.85 and img_params[ref][filename]['white_ratio'] < 0.99:\n",
    "             img_params[ref][filename]['use'] = 0\n",
    "        elif img_params[ref][filename]['mean'][0] < 20 or img_params[ref][filename]['mean'][0] > 245:\n",
    "             img_params[ref][filename]['use'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bfccd5e-c237-4d3f-b512-c16457a1568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2393040"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for ref in img_params:\n",
    "    for filename in img_params[ref]:\n",
    "        cnt += img_params[ref][filename]['use']\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf82675-8b97-4745-b8bb-3abeae7c9895",
   "metadata": {},
   "source": [
    "### Получение эмбедингов изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31b1768a-67f9-4ba0-b95f-ce5679b910ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39a6febe-6511-48de-a27e-ae721479ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_W, MIN_H = 128, 128\n",
    "BASE_DIR = pathlib.Path.cwd()\n",
    "BATCH = 8\n",
    "\n",
    "def safe_open(path: pathlib.Path):\n",
    "    \"\"\"\n",
    "    Открывает изображение, проверяя:\n",
    "      • файл существует и расширение поддерживается\n",
    "      • файл читается Pillow (не битый)\n",
    "      • размеры не меньше MIN_W×MIN_H\n",
    "    Возвращает объект PIL.Image или None, если не прошло валидацию.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            img.verify()             # быстрый тест на «битость»\n",
    "        img = Image.open(path).convert(\"RGB\")   # повторно открываем для чтения пикселей\n",
    "\n",
    "        if img.width < MIN_W or img.height < MIN_H:\n",
    "            return None\n",
    "        return img\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9626b94c-65ee-4849-9e78-d56f56cd30be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Processing folder: train_images_part_0001-chunk_0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11257/11257 [12:45<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90055 embeddings → train_images_part_0001-chunk_0001_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0001-chunk_0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11268/11268 [12:49<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90137 embeddings → train_images_part_0001-chunk_0002_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0001-chunk_0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11250/11250 [12:53<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 89998 embeddings → train_images_part_0001-chunk_0003_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0001-chunk_0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11269/11269 [13:00<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90150 embeddings → train_images_part_0001-chunk_0004_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0001-chunk_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11251/11251 [12:54<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90005 embeddings → train_images_part_0001-chunk_0005_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0001-chunk_0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11255/11255 [13:02<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90035 embeddings → train_images_part_0001-chunk_0006_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0001-chunk_0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|██████████████████████████████████████████████████████████████████| 5755/5755 [06:43<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 46039 embeddings → train_images_part_0001-chunk_0007_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0001-chunk_0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|██████████████████████████████████████████████████████████████████| 4399/4399 [05:03<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 35192 embeddings → train_images_part_0001-chunk_0008_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0002-chunk_0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11345/11345 [12:59<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90757 embeddings → train_images_part_0002-chunk_0001_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0002-chunk_0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11312/11312 [12:58<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90494 embeddings → train_images_part_0002-chunk_0002_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0002-chunk_0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11342/11342 [13:00<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90735 embeddings → train_images_part_0002-chunk_0003_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0002-chunk_0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11320/11320 [12:59<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90560 embeddings → train_images_part_0002-chunk_0004_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0002-chunk_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11316/11316 [13:02<00:00, 14.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90521 embeddings → train_images_part_0002-chunk_0005_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0002-chunk_0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11316/11316 [12:57<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90526 embeddings → train_images_part_0002-chunk_0006_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0002-chunk_0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|██████████████████████████████████████████████████████████████████| 6134/6134 [07:06<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 49067 embeddings → train_images_part_0002-chunk_0007_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0002-chunk_0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|██████████████████████████████████████████████████████████████████| 5899/5899 [06:53<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 47192 embeddings → train_images_part_0002-chunk_0008_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0003-chunk_0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11314/11314 [13:18<00:00, 14.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90511 embeddings → train_images_part_0003-chunk_0001_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0003-chunk_0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11308/11308 [13:09<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90459 embeddings → train_images_part_0003-chunk_0002_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0003-chunk_0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11308/11308 [13:18<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90457 embeddings → train_images_part_0003-chunk_0003_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0003-chunk_0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11305/11305 [13:10<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90437 embeddings → train_images_part_0003-chunk_0004_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0003-chunk_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11312/11312 [13:21<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90496 embeddings → train_images_part_0003-chunk_0005_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0003-chunk_0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11317/11317 [13:30<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90534 embeddings → train_images_part_0003-chunk_0006_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0003-chunk_0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|██████████████████████████████████████████████████████████████████| 7408/7408 [08:46<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 59261 embeddings → train_images_part_0003-chunk_0007_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0003-chunk_0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|██████████████████████████████████████████████████████████████████| 6042/6042 [07:04<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 48330 embeddings → train_images_part_0003-chunk_0008_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0004-chunk_0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11248/11248 [13:14<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 89980 embeddings → train_images_part_0004-chunk_0001_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0004-chunk_0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11269/11269 [13:13<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90146 embeddings → train_images_part_0004-chunk_0002_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0004-chunk_0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11258/11258 [13:07<00:00, 14.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90063 embeddings → train_images_part_0004-chunk_0003_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0004-chunk_0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|████████████████████████████████████████████████████████████████| 11256/11256 [13:09<00:00, 14.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 90042 embeddings → train_images_part_0004-chunk_0004_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0004-chunk_0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|██████████████████████████████████████████████████████████████████| 9060/9060 [10:34<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 72478 embeddings → train_images_part_0004-chunk_0005_embeddings.pt\n",
      "\n",
      "▶ Processing folder: train_images_part_0004-chunk_0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  batching: 100%|██████████████████████████████████████████████████████████████████| 6048/6048 [07:00<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 48383 embeddings → train_images_part_0004-chunk_0006_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "for folder in BASE_DIR.iterdir():\n",
    "    if not folder.is_dir():\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n▶ Processing folder: {folder.name}\")\n",
    "    image_paths = [p for p in folder.rglob(\"*\") if p.is_file()]\n",
    "    valid_image_paths = []\n",
    "    considered_path = img_params[folder.name]\n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            if considered_path[path.name]['use'] == 1:\n",
    "                valid_image_paths.append(path)\n",
    "        except:\n",
    "            continue\n",
    "    embeddings  = {}\n",
    "    skipped     = []\n",
    "\n",
    "    # батчами по BATCH штук\n",
    "    for i in tqdm(range(0, len(valid_image_paths), BATCH), desc=\"  batching\"):\n",
    "        batch = valid_image_paths[i : i + BATCH]\n",
    "        images, kept = [], []\n",
    "\n",
    "        for p in batch:\n",
    "            img = safe_open(p)\n",
    "            if img is None:\n",
    "                skipped.append(p)\n",
    "            else:\n",
    "                images.append(img)\n",
    "                kept.append(p)\n",
    "\n",
    "        if not images:\n",
    "            continue\n",
    "\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(**inputs)\n",
    "            vecs = out.pooler_output  # (len(kept), 768)\n",
    "\n",
    "        for path, vec in zip(kept, vecs):\n",
    "            embeddings[path.name] = vec.cpu()\n",
    "\n",
    "    # ── сохраняем словарь для этой папки\n",
    "    if embeddings:\n",
    "        out_file = folder.with_name(f\"{folder.name}_embeddings.pt\")\n",
    "        torch.save(embeddings, out_file)\n",
    "        print(f\"  Saved {len(embeddings)} embeddings → {out_file.name}\")\n",
    "    else:\n",
    "        print(\"  No embeddings to save in this folder.\")\n",
    "\n",
    "    if skipped:\n",
    "        print(f\"  Skipped {len(skipped)} files (too small or corrupt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea85f1ff-1e37-4056-b445-f1fbd560968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [02:02<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "merged = {}\n",
    "\n",
    "for f in tqdm(sorted(BASE_DIR.glob(\"*_embeddings.pt\"))):\n",
    "    chunk = torch.load(f, map_location=\"cpu\")   # {id: tensor}\n",
    "    merged.update(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "008b2fb3-d023-49fb-a787-17c780637cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f833b466-2fae-46b2-b512-1291fc467095",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(merged, \"train_images_embeddings_merged.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7fc80f-1f0d-447f-ab6a-066af5d7e5a9",
   "metadata": {},
   "source": [
    "### Mapping id -> jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34206271-00fe-4174-9fd8-f5109f644b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df_train[['base_item_id', 'base_title_image']]\n",
    "df_cand = df_train[['cand_item_id', 'cand_title_image']]\n",
    "\n",
    "base_ids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f745571-6869-4776-a524-091811103241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1879555/1879555 [00:29<00:00, 63302.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 1879555/1879555 [00:29<00:00, 63078.08it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(df_base.iterrows(), total=len(df_base)):\n",
    "    base_item_id = row[1].iloc[0]\n",
    "    base_title_image = row[1].iloc[1]\n",
    "    if base_item_id not in base_ids.keys():\n",
    "        base_ids[base_item_id] = base_title_image\n",
    "\n",
    "for row in tqdm(df_cand.iterrows(), total=len(df_cand)):\n",
    "    base_item_id = row[1].iloc[0]\n",
    "    base_title_image = row[1].iloc[1]\n",
    "    if base_item_id not in base_ids.keys():\n",
    "        base_ids[base_item_id] = base_title_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20b22b3b-3ce5-4d2d-8e0f-e85b137da48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_visual_emb = {}\n",
    "\n",
    "for item_id, image_name in base_ids.items():\n",
    "    img_format = image_name + '.jpg'\n",
    "    if img_format in merged:\n",
    "        items_visual_emb[item_id] = merged[img_format] \n",
    "    else:\n",
    "        items_visual_emb[item_id] = torch.zeros(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a67d21bc-333b-400b-ad94-bc4e9482cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(items_visual_emb, \"train_images_embeddings_merged.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d7c73-def1-4b53-ba47-6b7b580a077c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Количество картинок + регион"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed3b9bd-a210-42f4-b092-f3a43a69f7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cand_count_images\n",
       "1.0     368246\n",
       "3.0     230598\n",
       "2.0     223049\n",
       "10.0    214378\n",
       "4.0     205678\n",
       "5.0     184637\n",
       "6.0     137008\n",
       "7.0     101934\n",
       "8.0      93254\n",
       "9.0      88432\n",
       "NaN      32333\n",
       "11.0         6\n",
       "12.0         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['cand_count_images'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21269ba-1534-40ca-8266-935e74234a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "base_count_images\n",
       "1.0     363685\n",
       "3.0     228002\n",
       "10.0    219698\n",
       "2.0     218011\n",
       "4.0     204213\n",
       "5.0     183617\n",
       "6.0     138421\n",
       "7.0     105146\n",
       "8.0      95362\n",
       "9.0      90795\n",
       "NaN      32598\n",
       "11.0         7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['base_count_images'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "026ec95e-ab94-49d7-9895-9a9c84609859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_same_location\n",
       "True     1841435\n",
       "False      38120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_same_location'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e60524-b4fb-434f-b6f4-4e2413cfad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_same_region\n",
       "True     1854062\n",
       "False      25493\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_same_region'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0def4-4cff-45a3-b6bf-db41327deb58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Avito",
   "language": "python",
   "name": "avito"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
