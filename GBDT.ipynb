{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ca968-7000-4652-b6d2-f4c741f9a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity, rbf_kernel\n",
    "import math\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c9d46-d4c9-489c-b22a-ee98ab073bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('avitotech_data\\\\avitotech_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e8e8e-7c4c-4941-95d5-0b55b75d7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1 = pd.read_parquet(\"train_part_0001.snappy.parquet\")\n",
    "df_train_2 = pd.read_parquet(\"train_part_0002.snappy.parquet\")\n",
    "df_train_3 = pd.read_parquet(\"train_part_0003.snappy.parquet\")\n",
    "df_train_4 = pd.read_parquet(\"train_part_0004.snappy.parquet\")\n",
    "\n",
    "df_test_1 = pd.read_parquet(\"test_part_0001.snappy.parquet\")\n",
    "df_test_2 = pd.read_parquet(\"test_part_0002.snappy.parquet\")\n",
    "\n",
    "df_train = pd.concat([df_train_1, df_train_2, df_train_3, df_train_4])\n",
    "df_test = pd.concat([df_test_1, df_test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd421b-b4e8-47d0-ba48-091edf028360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['group_id', 'action_date', 'base_title',\n",
    "       'cand_title', 'base_description', 'cand_description',\n",
    "       'base_category_name', 'cand_category_name', 'base_subcategory_name',\n",
    "       'cand_subcategory_name', 'base_param1', 'cand_param1', 'base_param2',\n",
    "       'cand_param2', 'base_title_image', 'cand_title_image',\n",
    "       'is_same_location', 'is_same_region'], axis=1)\n",
    "\n",
    "df_test = df_test.drop(columns=['base_title',\n",
    "       'cand_title', 'base_description', 'cand_description',\n",
    "       'base_category_name', 'cand_category_name', 'base_subcategory_name',\n",
    "       'cand_subcategory_name', 'base_param1', 'cand_param1', 'base_param2',\n",
    "       'cand_param2', 'base_title_image', 'cand_title_image',\n",
    "       'is_same_location', 'is_same_region'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432567b4-144b-4923-8e78-1c16b0a34074",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_embed=torch.load(\"train_merged_embed.pt\", map_location=\"cpu\")\n",
    "test_merged_embed= torch.load(\"test_merged_embed.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48856336-ffdf-416e-aed9-15bf51c96fc4",
   "metadata": {},
   "source": [
    "# Model params range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e52be9-6800-4321-b922-9e2094f92704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(y_true, y_pred):\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true_sorted = np.array(y_true)[order]\n",
    "    n_positives = np.sum(y_true_sorted)\n",
    "    if n_positives == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    tp = 0\n",
    "    for k in range(1, len(y_true_sorted)+1):\n",
    "        if y_true_sorted[k-1] == 1:\n",
    "            tp += 1\n",
    "            precision = tp / k\n",
    "            recall = tp / n_positives\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "    delta_recalls = [recalls[0]] + [recalls[i] - recalls[i-1] for i in range(1, len(recalls))]\n",
    "    mAP = np.sum([p * dr for p, dr in zip(precisions, delta_recalls)])\n",
    "    return mAP\n",
    "\n",
    "def objective(trial):\n",
    "    # Подбор параметров\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 2200, 6000),\n",
    "        'depth': trial.suggest_int('depth', 7, 15),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.07, 0.25),\n",
    "        'l2_leaf_reg': trial.suggest_uniform('l2_leaf_reg', 5, 16),\n",
    "        'random_strength': trial.suggest_uniform('random_strength', 0, 2),\n",
    "        'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0.1, 0.8),\n",
    "        'eval_metric': 'Logloss',\n",
    "        'loss_function': 'Logloss',\n",
    "        'task_type': 'GPU',\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        df_extracted_train, y_train,\n",
    "        eval_set=(df_extracted_val, y_val),\n",
    "        use_best_model=False,\n",
    "        verbose=0\n",
    "    )\n",
    "    y_val_pred = model.predict_proba(df_extracted_val)[:, 1]\n",
    "    # ВАЖНО: возвращаем mAP, чтобы Optuna его максимизировал\n",
    "    return mean_average_precision(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45939e-7780-4dc5-8d36-08c927b37eac",
   "metadata": {},
   "source": [
    "# Build ids' items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268438f-d7d9-47a6-8472-3e1c1962bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = defaultdict()\n",
    "\n",
    "for row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    row_element = row[1]\n",
    "    \n",
    "    base_item_id = row_element['base_item_id']\n",
    "    cand_item_id = row_element['cand_item_id']\n",
    "\n",
    "    if base_item_id not in item_data:\n",
    "        \n",
    "        item_data[base_item_id] = {\n",
    "            'price':        row_element['base_price'],\n",
    "            'json_params':  row_element['base_json_params'],\n",
    "            'count_images': row_element['base_count_images'],\n",
    "        }\n",
    "\n",
    "    if cand_item_id not in item_data:\n",
    "        \n",
    "        item_data[cand_item_id] = {\n",
    "            'price':        row_element['cand_price'],\n",
    "            'json_params':  row_element['cand_json_params'],\n",
    "            'count_images': row_element['cand_count_images'],\n",
    "        }\n",
    "\n",
    "item_data_test = defaultdict()\n",
    "\n",
    "for row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    row_element = row[1]\n",
    "    \n",
    "    base_item_id = row_element['base_item_id']\n",
    "    cand_item_id = row_element['cand_item_id']\n",
    "\n",
    "    if base_item_id not in item_data_test:\n",
    "        \n",
    "        item_data_test[base_item_id] = {\n",
    "            'price':        row_element['base_price'],\n",
    "            'json_params':  row_element['base_json_params'],\n",
    "            'count_images': row_element['base_count_images'],\n",
    "        }\n",
    "\n",
    "    if cand_item_id not in item_data_test:\n",
    "        \n",
    "        item_data_test[cand_item_id] = {\n",
    "            'price':        row_element['cand_price'],\n",
    "            'json_params':  row_element['cand_json_params'],\n",
    "            'count_images': row_element['cand_count_images'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb60ea-61f0-4cdb-8f5e-1586cbc844ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info = defaultdict()\n",
    "\n",
    "for item_id, values in tqdm(item_data.items()):\n",
    "    if item_id in train_merged_embed.keys():\n",
    "        values['embed'] = train_merged_embed[item_id]\n",
    "        item_info[item_id] = values\n",
    "\n",
    "item_info_test = defaultdict()\n",
    "\n",
    "for item_id, values in tqdm(item_data_test.items()):\n",
    "    values['embed'] = test_merged_embed[item_id]\n",
    "    item_info_test[item_id] = values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266a8d2-cb5c-4dd3-a8ad-bbf105a578a4",
   "metadata": {},
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34987ef5-3232-489c-a323-c2fde12c5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y= []\n",
    "\n",
    "for row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    row_element = row[1]\n",
    "    \n",
    "    base_item_id = row_element['base_item_id']\n",
    "    cand_item_id = row_element['cand_item_id']\n",
    "\n",
    "    if base_item_id in item_info.keys() and cand_item_id in item_info.keys():\n",
    "        base_price = item_info[base_item_id]['price']\n",
    "        cand_price = item_info[cand_item_id]['price']\n",
    "\n",
    "        base_json_params = json.loads(item_info[base_item_id]['json_params'])\n",
    "        cand_json_params = json.loads(item_info[cand_item_id]['json_params'])\n",
    "\n",
    "        base_count_images = item_info[base_item_id]['count_images']\n",
    "        cand_count_images = item_info[cand_item_id]['count_images']\n",
    "\n",
    "        base_embed = item_info[base_item_id]['embed'].reshape(1, -1)\n",
    "        cand_embed = item_info[cand_item_id]['embed'].reshape(1, -1)\n",
    "\n",
    "        is_double = row_element['is_double']\n",
    "        # price\n",
    "        price_dif = 2 * abs(base_price - cand_price) / max((base_price + cand_price), 1)\n",
    "\n",
    "        # json\n",
    "        base_unique_keys = set(base_json_params.keys())\n",
    "        cand_unique_keys = set(cand_json_params.keys())\n",
    "\n",
    "        intersect = base_unique_keys.intersection(cand_unique_keys)\n",
    "        union = base_unique_keys.union(cand_unique_keys)\n",
    "\n",
    "        ## a. Jaccard\n",
    "        jaccard = 1 if len(union) == 0 else len(intersect) / len(union)\n",
    "\n",
    "        ## b. Ratio of intersect\n",
    "        ratio = 1 if len(union) == 0 else len(intersect) / max(min(len(base_unique_keys), len(cand_unique_keys)), 1)\n",
    "\n",
    "        ## c. shared\n",
    "        shared_int = 0\n",
    "        shared_float = 0\n",
    "        shared_str = 0\n",
    "        shared_list = 0\n",
    "        \n",
    "        intersect_int = 0\n",
    "        intersect_float = 0\n",
    "        intersect_str = 0\n",
    "        intersect_list = 0\n",
    "\n",
    "        for unique_key in intersect:\n",
    "            # int\n",
    "            if isinstance(base_json_params[unique_key], int) and isinstance(cand_json_params[unique_key], int):\n",
    "                intersect_int += 1\n",
    "                if base_json_params[unique_key] == cand_json_params[unique_key]:\n",
    "                    shared_int += 1\n",
    "\n",
    "            # float\n",
    "            if isinstance(base_json_params[unique_key], float) and isinstance(cand_json_params[unique_key], float):\n",
    "                intersect_float += 1\n",
    "                if base_json_params[unique_key] == cand_json_params[unique_key]:\n",
    "                    shared_float += 1\n",
    "\n",
    "            # str\n",
    "            if isinstance(base_json_params[unique_key], str) and isinstance(cand_json_params[unique_key], str):\n",
    "                intersect_str += 1\n",
    "                if base_json_params[unique_key] == cand_json_params[unique_key]:\n",
    "                    shared_str += 1\n",
    "\n",
    "            # list\n",
    "            if isinstance(base_json_params[unique_key], list) and isinstance(cand_json_params[unique_key], list):\n",
    "                intersect_list += 1\n",
    "                if len(base_json_params[unique_key]) == 0 or len(cand_json_params[unique_key]) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(base_json_params[unique_key][0], dict) or isinstance(cand_json_params[unique_key][0], dict):\n",
    "                    if set(base_json_params[unique_key][0].keys()) == set(cand_json_params[unique_key][0].keys()):\n",
    "                        shared_list += 1\n",
    "                elif set(base_json_params[unique_key]) == set(cand_json_params[unique_key]):\n",
    "                    shared_list += 1\n",
    "\n",
    "        shared = shared_int + shared_float + shared_str + shared_list\n",
    "\n",
    "        same_items_ratio       = shared / max(len(intersect), 1)\n",
    "        same_items_ratio_int   = shared_int / max(intersect_int, 1)\n",
    "        same_items_ratio_float = shared_float / max(intersect_float, 1)\n",
    "        same_items_ratio_str   = shared_str / max(intersect_str, 1)\n",
    "        same_items_ratio_list  = shared_list / max(intersect_list, 1)\n",
    "\n",
    "        # jaccard per type\n",
    "        union_int = set()\n",
    "        union_float = set()\n",
    "        union_str = set()\n",
    "        union_list = set()\n",
    "\n",
    "        for key, value in base_json_params.items():\n",
    "            if isinstance(value, int):\n",
    "                union_int.add(key)\n",
    "            elif isinstance(value, float):\n",
    "                union_float.add(key)\n",
    "            elif isinstance(value, str):\n",
    "                union_str.add(key)\n",
    "            elif isinstance(value, list):\n",
    "                union_list.add(key)\n",
    "\n",
    "        for key, value in cand_json_params.items():\n",
    "            if isinstance(value, int):\n",
    "                union_int.add(key)\n",
    "            elif isinstance(value, float):\n",
    "                union_float.add(key)\n",
    "            elif isinstance(value, str):\n",
    "                union_str.add(key)\n",
    "            elif isinstance(value, list):\n",
    "                union_list.add(key)\n",
    "\n",
    "        jaccard_int = 1 if len(union_int) == 0 else intersect_int / len(union_int)\n",
    "        jaccard_float = 1 if len(union_float) == 0 else intersect_float / len(union_float)\n",
    "        jaccard_str = 1 if len(union_str) == 0 else intersect_str / len(union_str)\n",
    "        jaccard_list = 1 if len(union_list) == 0 else intersect_list / len(union_list)\n",
    "        \n",
    "        # img diff\n",
    "        img_diff = abs(0 if math.isnan(base_count_images) else base_count_images - 0 if math.isnan(cand_count_images) else cand_count_images)\n",
    "\n",
    "        # cosine_similarity\n",
    "        cos_sim = cosine_similarity(base_embed, cand_embed).item()\n",
    "\n",
    "        # rbf kernel\n",
    "        rbf = rbf_kernel(base_embed, cand_embed).item()\n",
    "\n",
    "        X.append(\n",
    "            {\n",
    "                'price_dif': round(price_dif),\n",
    "                'jaccard': round(jaccard, 5),\n",
    "                'jaccard_int': round(jaccard_int, 5),\n",
    "                'jaccard_float': round(jaccard_float, 5),\n",
    "                'jaccard_str': round(jaccard_str, 5),\n",
    "                'jaccard_list': round(jaccard_list, 5),\n",
    "                'ratio': round(ratio, 5),\n",
    "                'same_items_ratio': round(same_items_ratio, 5),\n",
    "                'same_items_ratio_int': round(same_items_ratio_int, 5),\n",
    "                'same_items_ratio_float': round(same_items_ratio_float, 5),\n",
    "                'same_items_ratio_str': round(same_items_ratio_str, 5),\n",
    "                'same_items_ratio_list': round(same_items_ratio_list, 5),\n",
    "                'img_diff': round(img_diff),\n",
    "                'cos_sim': round(cos_sim, 5),\n",
    "                'rbf': round(rbf, 5)\n",
    "            }\n",
    "        )\n",
    "\n",
    "        y.append(is_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f246cf39-9fb5-4710-ae22-8b8da3be9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "for row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    row_element = row[1]\n",
    "    \n",
    "    base_item_id = row_element['base_item_id']\n",
    "    cand_item_id = row_element['cand_item_id']\n",
    "\n",
    "    if base_item_id in item_info_test.keys() and cand_item_id in item_info_test.keys():\n",
    "        base_price = item_info_test[base_item_id]['price']\n",
    "        cand_price = item_info_test[cand_item_id]['price']\n",
    "\n",
    "        base_json_params = json.loads(item_info_test[base_item_id]['json_params'])\n",
    "        cand_json_params = json.loads(item_info_test[cand_item_id]['json_params'])\n",
    "\n",
    "        base_count_images = item_info_test[base_item_id]['count_images']\n",
    "        cand_count_images = item_info_test[cand_item_id]['count_images']\n",
    "\n",
    "        base_embed = item_info_test[base_item_id]['embed'].reshape(1, -1)\n",
    "        cand_embed = item_info_test[cand_item_id]['embed'].reshape(1, -1)\n",
    "\n",
    "        # price\n",
    "        price_dif = 2 * abs(base_price - cand_price) / max((base_price + cand_price), 1)\n",
    "\n",
    "        # json\n",
    "        base_unique_keys = set(base_json_params.keys())\n",
    "        cand_unique_keys = set(cand_json_params.keys())\n",
    "\n",
    "        intersect = base_unique_keys.intersection(cand_unique_keys)\n",
    "        union = base_unique_keys.union(cand_unique_keys)\n",
    "\n",
    "        ## a. Jaccard\n",
    "        jaccard = 1 if len(union) == 0 else len(intersect) / len(union)\n",
    "\n",
    "        ## b. Ratio of intersect\n",
    "        ratio = 1 if len(union) == 0 else len(intersect) / max(min(len(base_unique_keys), len(cand_unique_keys)), 1)\n",
    "\n",
    "        ## c. shared\n",
    "        shared_int = 0\n",
    "        shared_float = 0\n",
    "        shared_str = 0\n",
    "        shared_list = 0\n",
    "        \n",
    "        intersect_int = 0\n",
    "        intersect_float = 0\n",
    "        intersect_str = 0\n",
    "        intersect_list = 0\n",
    "\n",
    "        for unique_key in intersect:\n",
    "            # int\n",
    "            if isinstance(base_json_params[unique_key], int) and isinstance(cand_json_params[unique_key], int):\n",
    "                intersect_int += 1\n",
    "                if base_json_params[unique_key] == cand_json_params[unique_key]:\n",
    "                    shared_int += 1\n",
    "\n",
    "            # float\n",
    "            if isinstance(base_json_params[unique_key], float) and isinstance(cand_json_params[unique_key], float):\n",
    "                intersect_float += 1\n",
    "                if base_json_params[unique_key] == cand_json_params[unique_key]:\n",
    "                    shared_float += 1\n",
    "\n",
    "            # str\n",
    "            if isinstance(base_json_params[unique_key], str) and isinstance(cand_json_params[unique_key], str):\n",
    "                intersect_str += 1\n",
    "                if base_json_params[unique_key] == cand_json_params[unique_key]:\n",
    "                    shared_str += 1\n",
    "\n",
    "            # list\n",
    "            if isinstance(base_json_params[unique_key], list) and isinstance(cand_json_params[unique_key], list):\n",
    "                intersect_list += 1\n",
    "                if len(base_json_params[unique_key]) == 0 or len(cand_json_params[unique_key]) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(base_json_params[unique_key][0], dict) or isinstance(cand_json_params[unique_key][0], dict):\n",
    "                    if set(base_json_params[unique_key][0].keys()) == set(cand_json_params[unique_key][0].keys()):\n",
    "                        shared_list += 1\n",
    "                elif set(base_json_params[unique_key]) == set(cand_json_params[unique_key]):\n",
    "                    shared_list += 1\n",
    "\n",
    "        shared = shared_int + shared_float + shared_str + shared_list\n",
    "\n",
    "        same_items_ratio       = shared / max(len(intersect), 1)\n",
    "        same_items_ratio_int   = shared_int / max(intersect_int, 1)\n",
    "        same_items_ratio_float = shared_float / max(intersect_float, 1)\n",
    "        same_items_ratio_str   = shared_str / max(intersect_str, 1)\n",
    "        same_items_ratio_list  = shared_list / max(intersect_list, 1)\n",
    "\n",
    "        # jaccard per type\n",
    "        union_int = set()\n",
    "        union_float = set()\n",
    "        union_str = set()\n",
    "        union_list = set()\n",
    "\n",
    "        for key, value in base_json_params.items():\n",
    "            if isinstance(value, int):\n",
    "                union_int.add(key)\n",
    "            elif isinstance(value, float):\n",
    "                union_float.add(key)\n",
    "            elif isinstance(value, str):\n",
    "                union_str.add(key)\n",
    "            elif isinstance(value, list):\n",
    "                union_list.add(key)\n",
    "\n",
    "        for key, value in cand_json_params.items():\n",
    "            if isinstance(value, int):\n",
    "                union_int.add(key)\n",
    "            elif isinstance(value, float):\n",
    "                union_float.add(key)\n",
    "            elif isinstance(value, str):\n",
    "                union_str.add(key)\n",
    "            elif isinstance(value, list):\n",
    "                union_list.add(key)\n",
    "\n",
    "        jaccard_int = 1 if len(union_int) == 0 else intersect_int / len(union_int)\n",
    "        jaccard_float = 1 if len(union_float) == 0 else intersect_float / len(union_float)\n",
    "        jaccard_str = 1 if len(union_str) == 0 else intersect_str / len(union_str)\n",
    "        jaccard_list = 1 if len(union_list) == 0 else intersect_list / len(union_list)\n",
    "        \n",
    "        # img diff\n",
    "        img_diff = abs(0 if math.isnan(base_count_images) else base_count_images - 0 if math.isnan(cand_count_images) else cand_count_images)\n",
    "\n",
    "        # cosine_similarity\n",
    "        cos_sim = cosine_similarity(base_embed, cand_embed).item()\n",
    "\n",
    "        # rbf kernel\n",
    "        rbf = rbf_kernel(base_embed, cand_embed).item()\n",
    "\n",
    "        X_test.append(\n",
    "            {\n",
    "                'price_dif': round(price_dif),\n",
    "                'jaccard': round(jaccard, 5),\n",
    "                'jaccard_int': round(jaccard_int, 5),\n",
    "                'jaccard_float': round(jaccard_float, 5),\n",
    "                'jaccard_str': round(jaccard_str, 5),\n",
    "                'jaccard_list': round(jaccard_list, 5),\n",
    "                'ratio': round(ratio, 5),\n",
    "                'same_items_ratio': round(same_items_ratio, 5),\n",
    "                'same_items_ratio_int': round(same_items_ratio_int, 5),\n",
    "                'same_items_ratio_float': round(same_items_ratio_float, 5),\n",
    "                'same_items_ratio_str': round(same_items_ratio_str, 5),\n",
    "                'same_items_ratio_list': round(same_items_ratio_list, 5),\n",
    "                'img_diff': round(img_diff),\n",
    "                'cos_sim': round(cos_sim, 5),\n",
    "                'rbf': round(rbf, 5)\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78a1af-a82a-4a18-b538-879beae15af9",
   "metadata": {},
   "source": [
    "# Split and build the optim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740d1f5-bd5d-413f-a290-e53d8637e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee79664-20c5-4d0b-866d-249c6a030460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_train = pd.DataFrame(X_train)\n",
    "df_extracted_val = pd.DataFrame(X_val)\n",
    "\n",
    "df_extracted_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288bbde6-6e40-4dfa-9943-4fd7dbe9190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=150)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best mAP:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f655f3-bc9b-43f6-aca0-95d30bf96a17",
   "metadata": {},
   "source": [
    "## Discovery the best range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01564a2-644c-437e-bb04-621688d5f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = []\n",
    "depth = []\n",
    "learning_rate =[]\n",
    "l2_leaf_reg= []\n",
    "random_strength =[]\n",
    "bagging_temperature = []\n",
    "metric = []\n",
    "\n",
    "for t in study.trials:\n",
    "    iterations.append(t.params['iterations'])\n",
    "    depth.append(t.params['depth'])\n",
    "    learning_rate.append(t.params['learning_rate'])\n",
    "    l2_leaf_reg.append(t.params['l2_leaf_reg'])\n",
    "    random_strength.append(t.params['random_strength'])\n",
    "    bagging_temperature.append(t.params['bagging_temperature'])\n",
    "\n",
    "    metric.append(t.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d904e-3a55-4383-862c-339c1b34c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'iterations',\n",
    "    'depth',\n",
    "    'learning_rate',\n",
    "    'l2_leaf_reg',\n",
    "    'random_strength',\n",
    "    'bagging_temperature'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026b33d-abe3-4241-b3eb-4347bbdca81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = {\n",
    "    'iterations':          100,\n",
    "    'depth':               1,\n",
    "    'learning_rate':       0.01,\n",
    "    'l2_leaf_reg':         1,\n",
    "    'random_strength':     0.1,\n",
    "    'bagging_temperature': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f45153-f46f-4add-b64f-1c041e28a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array = np.array(metric)\n",
    "metric_norm = (metric_array - metric_array.min()) / (metric_array.max() - metric_array.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854fa035-0253-432d-8026-b32b45f90040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correction = pd.DataFrame({'iterations': iterations,\n",
    "                              'depth': depth,\n",
    "                              'learning_rate': learning_rate,\n",
    "                              'l2_leaf_reg': l2_leaf_reg,\n",
    "                              'random_strength': random_strength,\n",
    "                              'bagging_temperature': bagging_temperature,\n",
    "                              'metric_norm': metric_norm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e90337-09c1-4315-a28f-ad4887a073e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_dict = {}\n",
    "labels_dict = {}\n",
    "\n",
    "for col in cols:\n",
    "    mn = df_correction[col].min()\n",
    "    mx = df_correction[col].max()\n",
    "    step = steps[col]\n",
    "    # создаём бины\n",
    "    bins = np.arange(mn, mx + step, step)\n",
    "    bins_dict[col] = bins\n",
    "    # выбираем формат меток\n",
    "    fmt = \".2f\" if step < 1 else \".0f\"\n",
    "    # создаём метки\n",
    "    labels = [f\"{bins[i]:{fmt}}-{bins[i+1]:{fmt}}\" for i in range(len(bins)-1)]\n",
    "    labels_dict[col] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee6250-5c43-4683-ab3a-f587d44d6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    df_correction[col] = pd.cut(\n",
    "        df_correction[col],\n",
    "        bins=bins_dict[col],\n",
    "        labels=labels_dict[col],\n",
    "        include_lowest=True,\n",
    "        right=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3fd99-c5ab-4f04-8c02-37b39108e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    agg = (\n",
    "        df_correction\n",
    "        .groupby(col, observed=False)['metric_norm']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.bar(agg[col].astype(str), agg['metric_norm'])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title(f'Sum of metric_norm by {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Sum of metric_norm')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210be284-9bb7-4307-a6ba-6f01f69f063d",
   "metadata": {},
   "source": [
    "# Retrain the model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c06ec-cf81-49d0-a112-8e6ccf4e22b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "best_model = CatBoostClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66ebcbe8-cc89-4351-9516-07f2ceaa1813",
   "metadata": {},
   "source": [
    "{'iterations': 2768,\n",
    " 'depth': 9,\n",
    " 'learning_rate': 0.07598421890276656,\n",
    " 'l2_leaf_reg': 8.360932120051347,\n",
    " 'random_strength': 0.6492554026970025,\n",
    " 'bagging_temperature': 0.4031354082805621}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839095ba-8565-4a24-bd1b-77fef7610e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(\n",
    "    pd.concat([df_extracted_train, df_extracted_val]),\n",
    "    y_train + y_val,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8428c-67c2-441e-a6fb-0beafab7650c",
   "metadata": {},
   "source": [
    "# Predict params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff37101-5c3b-43ca-bb2c-2ca5dfb53bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['base_price', 'cand_price',\n",
    "       'base_json_params', 'cand_json_params', 'base_count_images',\n",
    "       'cand_count_images'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80825e90-3413-4ebf-9b43-364a1cb95f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = y_test_proba.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec3603-8a0e-4dcf-9131-623c0d159671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"y_test_proba\"] = y_test_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a4192-ea10-4679-afaf-a245d8a32925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.rename(columns={\n",
    "    df_test.columns[0]: \"base_id\",\n",
    "    df_test.columns[1]: \"cand_id\",\n",
    "    df_test.columns[2]: \"probability\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434664d6-e400-4a48-afcb-f4e604a89e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"submission.csv\", index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee8cc7-6f99-45be-b30f-83ae9022cf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Avito",
   "language": "python",
   "name": "avito"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
